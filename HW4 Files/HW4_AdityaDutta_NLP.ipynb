{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24dc9fbd",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accfa96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in c:\\users\\adity\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torchtext) (4.65.0)\n",
      "Requirement already satisfied: requests in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: torch==2.2.1 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torchtext) (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torchtext) (1.24.3)\n",
      "Requirement already satisfied: torchdata==0.7.1 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torchtext) (0.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchtext) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchtext) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchtext) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchtext) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchtext) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torch==2.2.1->torchtext) (2023.4.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from torchdata==0.7.1->torchtext) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from requests->torchtext) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\anaconda3\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from jinja2->torch==2.2.1->torchtext) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from sympy->torch==2.2.1->torchtext) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b6b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from collections import Counter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae14f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cef8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab_from_data(file_path, tokenizer):\n",
    "    counter = Counter()\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            counter.update(tokenizer(line.strip()))\n",
    "    token_lists = [[token] for token in counter.keys()]\n",
    "    vocab = build_vocab_from_iterator(token_lists, specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d6e996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tags_vocab(file_path):\n",
    "    tags_counter = Counter()\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 3:\n",
    "                _, _, tag = parts\n",
    "                tags_counter.update([tag])\n",
    "    tag_lists = [[tag] for tag in tags_counter.keys()]\n",
    "    tags_vocab = build_vocab_from_iterator(tag_lists, specials=[\"O\", \"<unk>\", \"<pad>\"])\n",
    "    tags_vocab.set_default_index(tags_vocab[\"<unk>\"])\n",
    "    return tags_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95755521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 3684\n",
      "First test sentence length: 12\n",
      "First test sentence tokens: [16344, 79, 9935, 8260, 11138, 18952, 78, 4832, 9434, 17087, 5975, 99]\n",
      "Number of tokenized test sentences: 3684\n",
      "First few tokens of the first test sentence: [16344, 79, 9935, 8260, 11138, 18952, 78, 4832, 9434, 17087]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_index_test_data(file_path, text_vocab):\n",
    "    tokenized_texts = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        tokens = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:  # If line not empty\n",
    "                token = line.split()[1]  \n",
    "                tokens.append(token)\n",
    "            else:  \n",
    "                if tokens:  # If there are collected tokens for this sentence\n",
    "                    tokenized_texts.append([text_vocab[token.lower()] for token in tokens])\n",
    "                    tokens = []  # Reset \n",
    "        if tokens:  # Add last sentence if file doesn't end with newline\n",
    "            tokenized_texts.append([text_vocab[token.lower()] for token in tokens])\n",
    "    return tokenized_texts\n",
    "\n",
    "# Tokenizing and indexing test data\n",
    "test_texts = tokenize_and_index_test_data(r\"C:\\Users\\adity\\Desktop\\NLP\\HW4 Submission files\\hw4\\data\\test\", vocab)\n",
    "\n",
    "\n",
    "print(\"Number of test sentences:\", len(test_texts))\n",
    "if test_texts:\n",
    "    print(\"First test sentence length:\", len(test_texts[0]))\n",
    "    print(\"First test sentence tokens:\", test_texts[0])\n",
    "else:\n",
    "    print(\"Test data is empty after tokenization and indexing.\")\n",
    "\n",
    "    \n",
    "test_texts = tokenize_and_index_test_data(r\"C:\\Users\\adity\\Desktop\\NLP\\HW4 Submission files\\hw4\\data\\test\", vocab)  \n",
    "\n",
    "# After tokenizing and indexing your test data\n",
    "print(\"Number of tokenized test sentences:\", len(test_texts))\n",
    "if test_texts:\n",
    "    print(\"First few tokens of the first test sentence:\", test_texts[0][:10])\n",
    "else:\n",
    "    print(\"Test data is empty after tokenization and indexing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e9b8417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokenized test texts (first 5 sentences):\n",
      "Sentence 1: soccer - japan get lucky win , china in surprise defeat .\n",
      "Sentence 2: <unk> <unk>\n",
      "Sentence 3: <unk> , united arab emirates <unk>\n",
      "Sentence 4: japan began the defence of their asian cup title with a lucky 2-1 win against syria in a group c championship match on friday .\n",
      "Sentence 5: but china saw their luck desert them in the second match of the group , crashing to a surprise 2-0 defeat to newcomers <unk> .\n"
     ]
    }
   ],
   "source": [
    "# Printing first 5 sentences of tokenized test data\n",
    "print(\"Sample tokenized test texts (first 5 sentences):\")\n",
    "for i, test_text in enumerate(test_texts[:5]):\n",
    "    decoded_sentence = [vocab.get_itos()[token] for token in test_text]  # Convert back to words for easy reading\n",
    "    print(f\"Sentence {i + 1}: {' '.join(decoded_sentence)}\")\n",
    "\n",
    "test_texts, _ = tokenize_and_index_data(r\"C:\\Users\\adity\\Desktop\\NLP\\HW4 Submission files\\hw4\\data\\test\", vocab, tags_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1bccb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_data(r\"C:\\Users\\adity\\Desktop\\NLP\\HW4 Submission files\\hw4\\data\\train\", tokenizer)\n",
    "tags_vocab = build_tags_vocab(r\"C:\\Users\\adity\\Desktop\\NLP\\HW4 Submission files\\hw4\\data\\train\")\n",
    "\n",
    "# Tokenizing and indexing dataset\n",
    "train_texts, train_tags = tokenize_and_index_data(r\"C:\\Users\\adity\\Desktop\\NLP\\HW4 Submission files\\hw4\\data\\train\", vocab, tags_vocab)\n",
    "validation_texts, validation_tags = tokenize_and_index_data(r\"C:\\Users\\adity\\Desktop\\NLP\\HW4 Submission files\\hw4\\data\\dev\", vocab, tags_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "506d5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        return predictions\n",
    "\n",
    "# Model initialization\n",
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(tags_vocab)\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = BLSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c2f253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(texts, tags, batch_size, device, is_test=False):\n",
    "    # Debugging- initial condition of texts\n",
    "    print(f\"Entering create_batches with {'test' if is_test else 'train/validation'} data:\")\n",
    "    print(f\"Initial number of sentences: {len(texts)}\")\n",
    "    if is_test:\n",
    "        # For test data (no tags), check no empty sentences\n",
    "        filtered_texts = [text for text in texts if len(text) > 0]\n",
    "        # Debugging- remains after filtering\n",
    "        print(f\"Number of non-empty test texts after filtering: {len(filtered_texts)}\")\n",
    "        if not filtered_texts:\n",
    "            raise ValueError(\"All test sentences are empty after filtering.\")\n",
    "        # Preparing tensors\n",
    "        text_tensors = [torch.tensor(text, dtype=torch.long) for text in filtered_texts]\n",
    "        # Dummy tag tensors \n",
    "        tag_tensors = [torch.zeros(len(text), dtype=torch.long) for text in filtered_texts]\n",
    "    else:\n",
    "        # For training/validation data,we filter out pairs where text or tag is empty\n",
    "        filtered_pairs = [(text, tag) for text, tag in zip(texts, tags) if len(text) > 0 and len(tag) > 0]\n",
    "        # Separating the filtered texts and tags back out\n",
    "        filtered_texts = [pair[0] for pair in filtered_pairs]\n",
    "        filtered_tags = [pair[1] for pair in filtered_pairs]\n",
    "        # Debugging- what remains after filtering\n",
    "        print(f\"Number of non-empty train/validation texts after filtering: {len(filtered_texts)}\")\n",
    "        if not filtered_texts or not filtered_tags:\n",
    "            raise ValueError(\"No valid sentences or tags found. Check your data preprocessing and file contents.\")\n",
    "        # Preparing tensors\n",
    "        text_tensors = [torch.tensor(text, dtype=torch.long) for text in filtered_texts]\n",
    "        tag_tensors = [torch.tensor(tag, dtype=torch.long) for text, tag in filtered_pairs]\n",
    "    \n",
    "    # Preparing the final dataset and dataloader\n",
    "    dataset = TensorDataset(\n",
    "        torch.nn.utils.rnn.pad_sequence(text_tensors, batch_first=True, padding_value=vocab['<pad>']),\n",
    "        torch.nn.utils.rnn.pad_sequence(tag_tensors, batch_first=True, padding_value=tags_vocab['O'] if not is_test else 0)\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=not is_test)  \n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29c39631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering create_batches with train/validation data:\n",
      "Initial number of sentences: 14987\n",
      "Number of non-empty train/validation texts after filtering: 14987\n",
      "Entering create_batches with train/validation data:\n",
      "Initial number of sentences: 3466\n",
      "Number of non-empty train/validation texts after filtering: 3466\n",
      "Entering create_batches with test data:\n",
      "Initial number of sentences: 3684\n",
      "Number of non-empty test texts after filtering: 3684\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32  \n",
    "# Creating the data loaders\n",
    "train_dataloader = create_batches(train_texts, train_tags, BATCH_SIZE, device)\n",
    "valid_dataloader = create_batches(validation_texts, validation_tags, BATCH_SIZE, device)\n",
    "test_dataloader = create_batches(test_texts, [[]] * len(test_texts), BATCH_SIZE, device, is_test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff9ca521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "model = BLSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bcb62d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 0.10776411971526105\n",
      "Epoch 2: Training Loss: 0.07620487758107404\n",
      "Epoch 3: Training Loss: 0.06620039921134774\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3  # number of epochs\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for texts, tags in train_dataloader:\n",
    "        texts, tags = texts.to(device), tags.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(texts)\n",
    "        loss = loss_function(predictions.view(-1, OUTPUT_DIM), tags.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}: Training Loss: {total_loss / len(train_dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2264837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.07036589564533409\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for texts, tags in valid_dataloader:\n",
    "        texts, tags = texts.to(device), tags.to(device)\n",
    "        predictions = model(texts)\n",
    "        loss = loss_function(predictions.view(-1, OUTPUT_DIM), tags.view(-1))\n",
    "        total_loss += loss.item()\n",
    "    print(f'Validation Loss: {total_loss / len(valid_dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49e0ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "predictions_list = []\n",
    "with torch.no_grad():\n",
    "    for texts, _ in test_dataloader:  # Tags not needed for test data\n",
    "        texts = texts.to(device)\n",
    "        outputs = model(texts)\n",
    "        probabilities = torch.softmax(outputs, dim=-1)\n",
    "        predictions = torch.argmax(probabilities, dim=-1)\n",
    "        predictions_list.extend(predictions.cpu().numpy())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a83b1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model's state_dict\n",
    "torch.save(model.state_dict(), 'blstm1.pt')\n",
    "\n",
    "model.eval()\n",
    "dev_predictions = []\n",
    "with torch.no_grad():\n",
    "    for texts, _ in valid_dataloader:\n",
    "        texts = texts.to(device)\n",
    "        outputs = model(texts)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        dev_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "with open('dev1.out', 'w') as f:\n",
    "    for sentence_preds in dev_predictions:\n",
    "        for idx, tag_idx in enumerate(sentence_preds):\n",
    "            f.write(f\"{idx + 1} {tags_vocab.get_itos()[tag_idx]}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for texts, _ in test_dataloader:\n",
    "        texts = texts.to(device)\n",
    "        outputs = model(texts)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "with open('test1.out', 'w') as f:\n",
    "    for sentence_preds in test_predictions:\n",
    "        for idx, tag_idx in enumerate(sentence_preds):\n",
    "            f.write(f\"{idx + 1} {tags_vocab.get_itos()[tag_idx]}\\n\")\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ddf2e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.975, Recall: 0.981, F1-score: 0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Accumulating all actual tags and predicted tags from dev set\n",
    "all_dev_tags = []\n",
    "all_dev_preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for texts, tags in valid_dataloader:\n",
    "        texts, tags = texts.to(device), tags.to(device)\n",
    "        outputs = model(texts)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        all_dev_preds.extend(predictions.view(-1).cpu().numpy())\n",
    "        all_dev_tags.extend(tags.view(-1).cpu().numpy())\n",
    "\n",
    "# precision, recall, and F1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_dev_tags, all_dev_preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f'Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392c67c",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56e222aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_token(token):\n",
    "    if token.islower():\n",
    "        return f\"LOW_{token}\"\n",
    "    elif token.isupper():\n",
    "        return f\"UPP_{token}\"\n",
    "    elif token.istitle():\n",
    "        return f\"TITLE_{token}\"\n",
    "    else:\n",
    "        return f\"MISC_{token}\"  # For mixed or other cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f985fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_index_data(file_path, text_vocab, tokenizer, is_test=False):\n",
    "    tokenized_texts = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        tokens = []\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 3 or (is_test and len(parts) == 2):\n",
    "                token = parts[1] if is_test else parts[2]  \n",
    "                if not is_test:  # Only augmenting non-test tokens\n",
    "                    token = augment_token(token)\n",
    "                tokens.append(token)\n",
    "            else:  \n",
    "                if tokens:\n",
    "                    tokenized_texts.append([text_vocab[token.lower()] for token in tokens])  # Using lower to align with GloVe's case insensitivity\n",
    "                    tokens = []\n",
    "        if tokens:  # the last sentence\n",
    "            tokenized_texts.append([text_vocab[token.lower()] for token in tokens])\n",
    "    return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14b69751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(path):\n",
    "    \"\"\"Load the GloVe embeddings from a file.\"\"\"\n",
    "    embeddings_dict = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "    return embeddings_dict\n",
    "\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(r\"C:\\Users\\adity\\Desktop\\NLP\\HW4 Submission files\\hw4\\glove.6B.100d.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1ec2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100  \n",
    "\n",
    "def create_embedding_matrix(word_index, embedding_dict, dimension):\n",
    "    embedding_matrix = np.zeros((len(word_index), dimension))\n",
    "    for word, i in word_index.items():\n",
    "        if word in embedding_dict:\n",
    "            embedding_matrix[i] = embedding_dict[word]\n",
    "        else:\n",
    "            # Words not found in the embedding index = all-zeros.\n",
    "            embedding_matrix[i] = np.random.normal(scale=0.6, size=(dimension, ))\n",
    "    return embedding_matrix\n",
    "\n",
    "# vocab is vocabulary from training data\n",
    "embedding_matrix = create_embedding_matrix(vocab.get_stoi(), glove_embeddings, EMBEDDING_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57491a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        num_embeddings, embedding_dim = embedding_matrix.shape\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False  # Freeze embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        return predictions\n",
    "\n",
    "# Reinitializing model with new embedding layer\n",
    "model = BLSTM(embedding_matrix, HIDDEN_DIM, OUTPUT_DIM, DROPOUT).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "090f8415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 0.10047805314855789\n",
      "Epoch 2: Training Loss: 0.05664814013773317\n",
      "Epoch 3: Training Loss: 0.05019544748100899\n"
     ]
    }
   ],
   "source": [
    "# Re-define the optimizer \n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)  # Only parameters that require gradients (excluding frozen embeddings)\n",
    "\n",
    "N_EPOCHS = 3  \n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()  \n",
    "    total_loss = 0\n",
    "    for texts, tags in train_dataloader:\n",
    "        texts, tags = texts.to(device), tags.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(texts)\n",
    "        loss = criterion(predictions.view(-1, OUTPUT_DIM), tags.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}: Training Loss: {total_loss / len(train_dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c35646c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.05487297131859381\n",
      "Precision: 0.982, Recall: 0.986, F1-score: 0.983\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Switch to evaluation mode\n",
    "total_loss = 0\n",
    "all_dev_preds = []\n",
    "all_dev_tags = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, tags in valid_dataloader:\n",
    "        texts, tags = texts.to(device), tags.to(device)\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs.view(-1, OUTPUT_DIM), tags.view(-1))\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        all_dev_preds.extend(predictions.view(-1).cpu().numpy())\n",
    "        all_dev_tags.extend(tags.view(-1).cpu().numpy())\n",
    "\n",
    "print(f'Validation Loss: {total_loss / len(valid_dataloader)}')\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_dev_tags, all_dev_preds, average='weighted', zero_division=0)\n",
    "print(f'Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c03ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model state\n",
    "torch.save(model.state_dict(), 'blstm2.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb0d5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dev_predictions = []\n",
    "with torch.no_grad():\n",
    "    for texts, _ in valid_dataloader:\n",
    "        texts = texts.to(device)\n",
    "        outputs = model(texts)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        dev_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Save the development set predictions to dev2.out\n",
    "with open('dev2.out', 'w') as f:\n",
    "    for sentence_preds in dev_predictions:\n",
    "        for idx, tag_idx in enumerate(sentence_preds):\n",
    "            f.write(f\"{idx + 1} {tags_vocab.get_itos()[tag_idx]}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for texts, _ in test_dataloader:\n",
    "        texts = texts.to(device)\n",
    "        outputs = model(texts)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Save the test set predictions to test2.out\n",
    "with open('test2.out', 'w') as f:\n",
    "    for sentence_preds in test_predictions:\n",
    "        for idx, tag_idx in enumerate(sentence_preds):\n",
    "            f.write(f\"{idx + 1} {tags_vocab.get_itos()[tag_idx]}\\n\")\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900107f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
