{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df9e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATASET PREPARATION\n",
    "\n",
    "#Loading Data\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edb4954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_1820\\3622204569.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, sep='\\t', on_bad_lines=\"skip\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
      "0                US     43081963  R18RVCKGH1SSI9  B001BM2MAC       307809868   \n",
      "1                US     10951564  R3L4L6LW1PUOFY  B00DZYEXPQ        75004341   \n",
      "2                US     21143145  R2J8AWXWTDX2TF  B00RTMUHDW       529689027   \n",
      "3                US     52782374  R1PR37BR7G3M6A  B00D7H8XB6       868449945   \n",
      "4                US     24045652  R3BDDDZMZBZDPU  B001XCWP34        33521401   \n",
      "...             ...          ...             ...         ...             ...   \n",
      "2640249          US     53005790   RLI7EI10S7SN0  B00000DM9M       223408988   \n",
      "2640250          US     52188548  R1F3SRK9MHE6A3  B00000DM9M       223408988   \n",
      "2640251          US     52090046  R23V0C4NRJL8EM  0807865001       307284585   \n",
      "2640252          US     52503173  R13ZAE1ATEUC1T  1572313188       870359649   \n",
      "2640253          US     52585611   RE8J5O2GY04NN  1572313188       870359649   \n",
      "\n",
      "                                             product_title product_category  \\\n",
      "0           Scotch Cushion Wrap 7961, 12 Inches x 100 Feet  Office Products   \n",
      "1                Dust-Off Compressed Gas Duster, Pack of 4  Office Products   \n",
      "2        Amram Tagger Standard Tag Attaching Tagging Gu...  Office Products   \n",
      "3        AmazonBasics 12-Sheet High-Security Micro-Cut ...  Office Products   \n",
      "4        Derwent Colored Pencils, Inktense Ink Pencils,...  Office Products   \n",
      "...                                                    ...              ...   \n",
      "2640249                 PalmOne III Leather Belt Clip Case  Office Products   \n",
      "2640250                 PalmOne III Leather Belt Clip Case  Office Products   \n",
      "2640251                  Gods and Heroes of Ancient Greece  Office Products   \n",
      "2640252  Microsoft EXCEL 97/ Visual Basic Step-by-Step ...  Office Products   \n",
      "2640253  Microsoft EXCEL 97/ Visual Basic Step-by-Step ...  Office Products   \n",
      "\n",
      "        star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
      "0                 5            0.0          0.0    N                 Y   \n",
      "1                 5            0.0          1.0    N                 Y   \n",
      "2                 5            0.0          0.0    N                 Y   \n",
      "3                 1            2.0          3.0    N                 Y   \n",
      "4                 4            0.0          0.0    N                 Y   \n",
      "...             ...            ...          ...  ...               ...   \n",
      "2640249           4           26.0         26.0    N                 N   \n",
      "2640250           4           18.0         18.0    N                 N   \n",
      "2640251           4            9.0         16.0    N                 N   \n",
      "2640252           5            0.0          0.0    N                 N   \n",
      "2640253           5            0.0          0.0    N                 N   \n",
      "\n",
      "                                           review_headline  \\\n",
      "0                                               Five Stars   \n",
      "1        Phffffffft, Phfffffft. Lots of air, and it's C...   \n",
      "2                            but I am sure I will like it.   \n",
      "3        and the shredder was dirty and the bin was par...   \n",
      "4                                               Four Stars   \n",
      "...                                                    ...   \n",
      "2640249  Great value! A must if you hate to carry thing...   \n",
      "2640250          Attaches the Palm Pilot like an appendage   \n",
      "2640251  Excellent information, pictures and stories, I...   \n",
      "2640252                                         class text   \n",
      "2640253                                 Microsoft's Finest   \n",
      "\n",
      "                                               review_body review_date  \n",
      "0                                           Great product.  2015-08-31  \n",
      "1        What's to say about this commodity item except...  2015-08-31  \n",
      "2          Haven't used yet, but I am sure I will like it.  2015-08-31  \n",
      "3        Although this was labeled as &#34;new&#34; the...  2015-08-31  \n",
      "4                          Gorgeous colors and easy to use  2015-08-31  \n",
      "...                                                    ...         ...  \n",
      "2640249  I can't live anymore whithout my Palm III. But...  1998-12-07  \n",
      "2640250  Although the Palm Pilot is thin and compact it...  1998-11-30  \n",
      "2640251  This book had a lot of great content without b...  1998-10-15  \n",
      "2640252  I am teaching a course in Excel and am using t...  1998-08-22  \n",
      "2640253  A very comprehensive layout of exactly how Vis...  1998-07-15  \n",
      "\n",
      "[2640254 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Users\\adity\\Desktop\\NLP\\amazon_reviews_us_Office_Products_v1_00.tsv\"\n",
    "data = pd.read_csv(file_path, sep='\\t', on_bad_lines=\"skip\")\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bebfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['review_body', 'star_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd75043",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['star_rating'] !=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a8babeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows with non-numeric 'star_rating' values: \n",
    "data = data[pd.to_numeric(data['star_rating'], errors='coerce').notnull()]\n",
    "\n",
    "#Converting 'star_rating' to integers: \n",
    "data['star_rating'] = data['star_rating'].astype(int)\n",
    "\n",
    "#Function:\n",
    "data['Sentiment'] = data['star_rating'].apply(lambda rating : +1 if rating > 3 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eccd816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               review_body  star_rating  \\\n",
      "0                                           Great product.            5   \n",
      "1        What's to say about this commodity item except...            5   \n",
      "2          Haven't used yet, but I am sure I will like it.            5   \n",
      "3        Although this was labeled as &#34;new&#34; the...            1   \n",
      "4                          Gorgeous colors and easy to use            4   \n",
      "...                                                    ...          ...   \n",
      "2640249  I can't live anymore whithout my Palm III. But...            4   \n",
      "2640250  Although the Palm Pilot is thin and compact it...            4   \n",
      "2640251  This book had a lot of great content without b...            4   \n",
      "2640252  I am teaching a course in Excel and am using t...            5   \n",
      "2640253  A very comprehensive layout of exactly how Vis...            5   \n",
      "\n",
      "         Sentiment  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                0  \n",
      "4                1  \n",
      "...            ...  \n",
      "2640249          1  \n",
      "2640250          1  \n",
      "2640251          1  \n",
      "2640252          1  \n",
      "2640253          1  \n",
      "\n",
      "[2460366 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e626f723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 2001183\n",
      "Number of negative reviews: 459183\n"
     ]
    }
   ],
   "source": [
    "#Printing no. of reviews for each sentiment: \n",
    "print('Number of positive reviews:', len(data[data['Sentiment'] == 1]))\n",
    "print('Number of negative reviews:', len(data[data['Sentiment'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72866fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting 100,000 positive reviews and 100,000 negative reviews: \n",
    "data_pos = data[data['Sentiment'] == 1].sample(n=100000)\n",
    "data_neg = data[data['Sentiment'] == 0].sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a3e0c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               review_body  star_rating  \\\n",
      "1919276  I'm in school for accounting and use a lot of ...            4   \n",
      "726405                         Thank you it's amazing item            5   \n",
      "1246962                      Great price, is working well.            5   \n",
      "2393875  This screen protector is a perfect cut to fit ...            5   \n",
      "396871   Although this is my first photo printer, I've ...            5   \n",
      "...                                                    ...          ...   \n",
      "1497376  I hoped this would produce some noise you coul...            1   \n",
      "1932136  the ink printed maybe 3 pages before it ran ou...            1   \n",
      "1299488                                     could not hear            1   \n",
      "736985                                 was not compatible.            1   \n",
      "177045   I feel somewhat ripped off. I bought the dark ...            2   \n",
      "\n",
      "         Sentiment  \n",
      "1919276          1  \n",
      "726405           1  \n",
      "1246962          1  \n",
      "2393875          1  \n",
      "396871           1  \n",
      "...            ...  \n",
      "1497376          0  \n",
      "1932136          0  \n",
      "1299488          0  \n",
      "736985           0  \n",
      "177045           0  \n",
      "\n",
      "[200000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenating the reviews:\n",
    "data2 = pd.concat([data_pos, data_neg])\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee576b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01f0403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in the training set: 160000\n",
      "Number of reviews in the testing set: 40000\n"
     ]
    }
   ],
   "source": [
    "#Splitting into training and testing sets: \n",
    "print('Number of reviews in the training set:', len(train_data))\n",
    "print('Number of reviews in the testing set:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cefa631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning\n",
    "\n",
    "import re\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = str(text)\n",
    "\n",
    "     # Convert text to lower case: \n",
    "    text = text.lower()\n",
    "\n",
    "     # Remove HTML tags: \n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Remove URLs: \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "     # Remove non-alphabetical characters: \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "     # Remove extra spaces:\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "#Apply Cleaning:\n",
    "data2['cleaned_review'] = data2['review_body'].apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a71359b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length before cleaning: 318.26275\n",
      "Average length after cleaning: 300.41638\n"
     ]
    }
   ],
   "source": [
    "#  Average review length before cleaning\n",
    "\n",
    "data2['review_length_before'] = data2['review_body'].astype(str).apply(len)\n",
    "avg_length_before = data2['review_length_before'].mean()\n",
    "\n",
    "# Apply the cleaning function\n",
    "data2['cleaned_review'] = data2['review_body'].apply(clean_text)\n",
    "\n",
    "#  Average review length after cleaning\n",
    "data2['review_length_after'] = data2['cleaned_review'].apply(len)\n",
    "avg_length_after = data2['review_length_after'].mean()\n",
    "\n",
    "print(\"Average length before cleaning:\", avg_length_before)\n",
    "print(\"Average length after cleaning:\", avg_length_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c8fc067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing:\n",
      "1919276    I'm in school for accounting and use a lot of ...\n",
      "726405                           Thank you it's amazing item\n",
      "1246962                        Great price, is working well.\n",
      "Name: review_body, dtype: object\n",
      "Average length before preprocessing: 318.26275\n",
      "After preprocessing:\n",
      "1919276    I'm school accounting use lot lead. This far b...\n",
      "726405                                    Thank amazing item\n",
      "1246962                           Great price, working well.\n",
      "Name: review_body, dtype: object\n",
      "Average length after preprocessing: 221.881355\n"
     ]
    }
   ],
   "source": [
    "# 3. PRE-PROCESSING\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Defining Stop words and Lemmatizer: \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    #Tokenization:  \n",
    "    reviews = reviews.str.split()\n",
    "    \n",
    "   #Removing stop words and perform lemmatization : \n",
    "    reviews = reviews.apply(lambda x: [lemmatizer.lemmatize(word) for word in x if word not in stop_words])\n",
    "    \n",
    "   #Joining back into single string:\n",
    "    reviews = reviews.str.join(' ')\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "# Print 3 sample reviews before preprocessing\n",
    "print('Before preprocessing:')\n",
    "print(data2['review_body'].head(3))\n",
    "\n",
    "data2['review_body'] = data2['review_body'].astype(str)\n",
    "\n",
    "#  Average length of the reviews before preprocessing\n",
    "average_length_before = data2['review_body'].apply(len).mean()\n",
    "print('Average length before preprocessing:', average_length_before)\n",
    "\n",
    "data2['review_body'] = preprocess_reviews(data2['review_body'])\n",
    "\n",
    "# Print 3 sample reviews after preprocessing\n",
    "print('After preprocessing:')\n",
    "print(data2['review_body'].head(3))\n",
    "\n",
    "# Average length of the reviews after preprocessing\n",
    "average_length_after = data2['review_body'].apply(len).mean()\n",
    "print('Average length after preprocessing:', average_length_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "406fc192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF features: (200000, 72739)\n"
     ]
    }
   ],
   "source": [
    "# 4. TF-IDF FEATURE EXTRACTION\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Transform the reviews into TF-IDF features: \n",
    "tfidf_features = vectorizer.fit_transform(data2['review_body'])\n",
    "\n",
    "# Print the shape of the TF-IDF features:\n",
    "print('Shape of TF-IDF features:', tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af02c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Training Metrics:\n",
      "Accuracy: 0.9076625\n",
      "Precision: 0.891211783191201\n",
      "Recall: 0.9287062382041571\n",
      "F1 Score: 0.9095727751254744\n",
      "\n",
      "Perceptron Testing Metrics:\n",
      "Accuracy: 0.855725\n",
      "Precision: 0.842006540977299\n",
      "Recall: 0.8756564797679187\n",
      "F1 Score: 0.85850190020841\n"
     ]
    }
   ],
   "source": [
    "# 5. PERCEPTRON MODEL\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets: \n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, data2['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Training the model:\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Using on training and testing data: \n",
    "y_train_pred = perceptron.predict(X_train)\n",
    "y_test_pred = perceptron.predict(X_test)\n",
    "\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print:\n",
    "print(\"Perceptron Training Metrics:\")\n",
    "print(\"Accuracy:\", train_accuracy)\n",
    "print(\"Precision:\", train_precision)\n",
    "print(\"Recall:\", train_recall)\n",
    "print(\"F1 Score:\", train_f1)\n",
    "\n",
    "print(\"\\nPerceptron Testing Metrics:\")\n",
    "print(\"Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", test_precision)\n",
    "print(\"Recall:\", test_recall)\n",
    "print(\"F1 Score:\", test_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a0e164c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Metrics:\n",
      "Accuracy: 0.91145625\n",
      "Precision: 0.9157405536472014\n",
      "Recall: 0.9063206969390178\n",
      "F1 Score: 0.9110062754803978\n",
      "\n",
      "Logistic Regression Testing Metrics:\n",
      "Accuracy: 0.897825\n",
      "Precision: 0.904485810192249\n",
      "Recall: 0.8895113289651378\n",
      "F1 Score: 0.8969360736351027\n",
      "\n",
      "\n",
      "Naive Bayes Training Metrics:\n",
      "Accuracy: 0.87785\n",
      "Precision: 0.8926627787663494\n",
      "Recall: 0.8590123364205632\n",
      "F1 Score: 0.8755143377622645\n",
      "\n",
      "Naive Bayes Testing Metrics:\n",
      "Accuracy: 0.862775\n",
      "Precision: 0.8777083333333333\n",
      "Recall: 0.8428950132546391\n",
      "F1 Score: 0.8599494807746281\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. lOGISTIC REGRESSION AND MULTINOMIAL NAIVE BAYES\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "log_reg_model = LogisticRegression(max_iter=1000)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "models = {'Logistic Regression': log_reg_model, 'Naive Bayes': nb_model}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"{name} Training Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "    print(\"Precision:\", precision_score(y_train, y_train_pred))\n",
    "    print(\"Recall:\", recall_score(y_train, y_train_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_train, y_train_pred))\n",
    "\n",
    "    print(f\"\\n{name} Testing Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_test_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_test_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_test_pred))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46072221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Accuracy: 0.97333125\n",
      "Precision: 0.9730202348238821\n",
      "Recall: 0.9736648043296211\n",
      "F1 score: 0.973342412864613\n",
      "Testing data:\n",
      "Accuracy: 0.907\n",
      "Precision: 0.9110796746324458\n",
      "Recall: 0.9019656879907968\n",
      "F1 score: 0.9064997737897753\n"
     ]
    }
   ],
   "source": [
    "# 7. SVM MODEL\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize the SVM model\n",
    "model = SVC()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training and testing data\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate and print the metrics for the training data\n",
    "print('Training data:')\n",
    "print('Accuracy:', accuracy_score(y_train, y_train_pred))\n",
    "print('Precision:', precision_score(y_train, y_train_pred))\n",
    "print('Recall:', recall_score(y_train, y_train_pred))\n",
    "print('F1 score:', f1_score(y_train, y_train_pred))\n",
    "\n",
    "# Calculate and print the metrics for the testing data\n",
    "print('Testing data:')\n",
    "print('Accuracy:', accuracy_score(y_test, y_test_pred))\n",
    "print('Precision:', precision_score(y_test, y_test_pred))\n",
    "print('Recall:', recall_score(y_test, y_test_pred))\n",
    "print('F1 score:', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee315f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
